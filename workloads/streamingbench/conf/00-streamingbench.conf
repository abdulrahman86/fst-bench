# default configurations here

# export for shell script
# dummy input/output path
hibench.workload.input                                     
hibench.workload.output  

# default scale factor
hibench.streamingbench.datagen.scale_factor                1

# default path setting for genearate data1 & data2
hibench.streamingbench.datagen.dir                         ${hibench.hdfs.data.dir}/Streaming
hibench.streamingbench.datagen.data1.name                  Seed
hibench.streamingbench.datagen.data1.dir                   ${hibench.streamingbench.datagen.dir}/${hibench.streamingbench.datagen.data1.name}

# Length limitation suggestion: 60 ~ 180
hibench.streamingbench.datagen.data1.length                60

hibench.streamingbench.datagen.data2_cluster.dir           ${hibench.streamingbench.datagen.dir}/Kmeans/Cluster
hibench.streamingbench.datagen.data2_samples.dir           ${hibench.streamingbench.datagen.dir}/Kmeans/Samples

# data scale for data1
hibench.workload.uservisits                                ${hibench.aggregation.small.uservisits}
hibench.workload.pages                                     ${hibench.aggregation.tiny.pages}

# data scale for data2
hibench.kmeans.num_of_clusters                             ${hibench.kmeans.tiny.num_of_clusters}
hibench.kmeans.dimensions                                  ${hibench.kmeans.small.dimensions}
hibench.kmeans.num_of_samples                              ${hibench.kmeans.tiny.num_of_samples}
hibench.kmeans.samples_per_inputfile                       ${hibench.kmeans.tiny.samples_per_inputfile}
hibench.kmeans.max_iteration                               ${hibench.kmeans.tiny.max_iteration}
hibench.kmeans.k                                           ${hibench.kmeans.tiny.k}
hibench.kmeans.convergedist                                ${hibench.kmeans.tiny.convergedist}
