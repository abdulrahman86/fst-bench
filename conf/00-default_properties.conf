hibench.spark.master		local[1]
hibench.report.formats		"%-12s %-10s %-8s %-20s %-20s %-20s %-20s\n"
hibench.hadoop.executable	${hibench.hadoop.home}/bin/hadoop
hibench.report.dir		${hibench.home}/report
hibench.report.name		hibench.report
hibench.dependency.dir		${hibench.home}/src
hibench.sparkbench.jar		${hibench.home}/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-jar-with-dependencies.jar
hibench.configure.dir		${hibench.home}/conf
hibench.sparkbenc.python.dir	${hibench.home}/src/sparkbench/src/main/python
hibench.hdfs.data.dir		${hibench.hdfs.master}/HiBench
hibench.hibench.datatool.dir	${hibench.home}/src/autogen/target/autogen-4.0-SNAPSHOT-jar-with-dependencies.jar

hibench.default.map.parallelism		2
hibench.default.shuffle.parallelism	2


hibench.hive.home		${hibench.dependency.dir}/hivebench/target/${hibench.hive.release}
hibench.hive.release		hive-0.12.0-bin
hibench.hivebench.template.dir	${hibench.dependency.dir}/hivebench/hive_template
hibench.hive.dir.name.input	${hibench.workload.dir.name.input}
hibench.hive.dir.name.ouput	${hibench.workload.dir.name.output}
hibench.kmeans.dir.name.input	${hibench.workload.dir.name.input}
hibench.kmeans.dir.name.output	${hibench.workload.dir.name.output}
hibench.bayes.dir.name.input	${hibench.workload.dir.name.input}
hibench.bayes.dir.name.output	${hibench.workload.dir.name.output}
hibench.pagerank.dir.name.input		${hibench.workload.dir.name.input}
hibench.pagerank.dir.name.output	${hibench.workload.dir.name.output}
hibench.pagerank.pegasus.dir		${hibench.dependency.dir}/pegasus/target/pegasus-2.0-SNAPSHOT.jar
hibench.mahout.home		${hibench.dependency.dir}/mahout/target/${hibench.mahout.release}
hibench.mahout.release.apache   mahout-distribution-0.9
hibench.mahout.release.cdh4	mahout-0.7-cdh4.7.1
hibench.mahout.release.cdh5	mahout-0.9-cdh5.1.0
hibench.mahout.release		${hibench.mahout.release.${hibench.hadoop.release}}

hibench.nutch.dir.name.input	${hibench.workload.dir.name.input}
hibench.nutch.dir.name.output	${hibench.workload.dir.name.output}
hibench.nutch.nutchindexing.dir	${hibench.dependency.dir}/nutchindexing/
hibench.nutch.release		nutch-1.2
hibench.nutch.home		${hibench.dependency.dir}/nutchindexing/target/${hibench.nutch.release}



hibench.randomtextwriter.bytespermap.hadoop1.name  test.randomtextwrite.bytes_per_map
hibench.randomtextwriter.mapsperhost.hadoop1.name  test.randomtextwrite.maps_per_host
hibench.randomtextwriter.bytespermap.hadoop2.name  mapreduce.randomtextwriter.bytespermap
hibench.randomtextwriter.mapsperhost.hadoop2.name  mapreduce.randomtextwriter.mapsperhost

hibench.randomtextwriter.bytespermap.name	${hibench.randomtextwriter.bytespermap.${hibench.hadoop.version}.name}
hibench.randomtextwriter.mapsperhost.name 	${hibench.randomtextwriter.mapsperhost.${hibench.hadoop.version}.name}

hibench.workload.dir.name.compress_disable.input	Input
hibench.workload.dir.name.compress_disable.output	Output
hibench.workload.dir.name.compress_enable.input		Input-comp-${hibench.compress.codec.profile}
hibench.workload.dir.name.compress_enable.output	Output-comp-${hibench.compress.codec.profile}

hibench.workload.dir.name.input				${hibench.workload.dir.name.compress_${hibench.compress.profile}.input}
hibench.workload.dir.name.output			${hibench.workload.dir.name.compress_${hibench.compress.profile}.output}


#compression options for hadoop
hibench.workload.compress.enable.options	"-D ${hibench.compress.map.output.compress.name}=true -D ${hibench.compress.map.output.compress.codec.name}=${hibench.compress.map.output.compress.codec.value} -D ${hibench.compress.output.fileoutputformat.compress.name}=true -D ${hibench.compress.output.fileoutputformat.compress.codec.name}=${hibench.compress.output.fileoutputformat.compress.codec.value} -D ${hibench.compress.output.fileoutputformat.compress.type.name}=BLOCK"
hibench.workload.compress.disable.options	"-D ${hibench.compress.output.fileoutputformat.compress.name}=false"
hibench.workload.compress.options	 	${hibench.workload.compress.${hibench.compress.profile}.options}

#compression options for sparkbecnh
sparkbench.codec.selection			${sparkbench.codec.${hibench.compress.profile}.options}
sparkbench.codec.disable.options		None
sparkbench.codec.enable.options			${hibench.compress.codec}

hibench.compress.map.output.compress.hadoop1.name			mapred.map.output.compress
hibench.compress.map.output.compress.codec.hadoop1.name			mapred.map.output.compress.codec
hibench.compress.output.fileoutputformat.compress.hadoop1.name		mapred.output.compress
hibench.compress.output.fileoutputformat.compress.codec.hadoop1.name	mapred.output.compression.codec
hibench.compress.output.fileoutputformat.compress.type.hadoop1.name	mapred.output.compression.type

hibench.compress.map.output.compress.hadoop2.name			mapreduce.map.output.compress
hibench.compress.map.output.compress.codec.hadoop2.name			mapreduce.map.output.compress.codec
hibench.compress.output.fileoutputformat.compress.hadoop2.name		mapreduce.output.fileoutputformat.compress
hibench.compress.output.fileoutputformat.compress.codec.hadoop2.name	mapreduce.output.fileoutputformat.compress.codec
hibench.compress.output.fileoutputformat.compress.type.hadoop2.name	mapreduce.output.fileoutputformat.compress.type

hibench.compress.map.output.compress.name				${hibench.compress.map.output.compress.${hibench.hadoop.version}.name}
hibench.compress.map.output.compress.codec.name				${hibench.compress.map.output.compress.codec.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.name			${hibench.compress.output.fileoutputformat.compress.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.codec.name		${hibench.compress.output.fileoutputformat.compress.codec.${hibench.hadoop.version}.name}
hibench.compress.output.fileoutputformat.compress.type.name		${hibench.compress.output.fileoutputformat.compress.type.${hibench.hadoop.version}.name}

hibench.compress.map.output.compress.codec.value			${hibench.compress.codec.map}
hibench.compress.output.fileoutputformat.compress.codec.value		${hibench.compress.codec}


# Compression codec profile relation
hibench.compress.codec			${hibench.compress.${hibench.compress.codec.profile}.codec}
# map codec share with global compression codec
hibench.compress.codec.map		${hibench.compress.${hibench.compress.codec.profile}.codec}

# Compress codec profiles
hibench.compress.snappy.codec		org.apache.hadoop.io.compress.SnappyCodec
hibench.compress.default.codec		org.apache.hadoop.io.compress.DefaultCodec
hibench.compress.lzo.codec		com.hadoop.compression.lzo.LzoCodec

# Scale profile: tiny, small, large, ..., defined in 30-data-scale-profile.conf
hibench.scale.profile  	      	     	tiny
# Compression options selection: enable, disable
hibench.compress.profile	 	enable
# Compression codec profile selection:	 snappy, lzo, default
hibench.compress.codec.profile		snappy


# Available formats: Text, Sequence. Defaults: Text
# Specifiy Compress codec, None -> no compress. Defaults: None
sparkbench.inputformat        Sequence
sparkbench.inputformat.codec  ${sparkbench.codec.selection}

sparkbench.outputformat        Sequence
sparkbench.outputformat.codec  ${sparkbench.codec.selection}