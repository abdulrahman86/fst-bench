# Sparkbench properties
# CPU cores per node * number of nodes, i.e. sum of all cpu cores in your cluster,
#   use taskScheduler.defaultParallelism as default if not specified
spark.default.parallelism     256

# Reducer number for terasort, default to spark.default.parallelism / 2 if not specified
sparkbench.reducer            128

# Available formats: Text, Sequence. Defaults: Text
# Specifiy Compress codec, None -> no compress. Defaults: None
sparkbench.inputformat        Sequence
sparkbench.inputformat.codec  None 
#sparkbench.intputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

sparkbench.outputformat       Sequence
sparkbench.outputformat.codec  None
#sparkbench.outputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

# Compression
spark.rdd.compress            false
# compression codec: lz4, lzf, snappy
spark.io.compression.codec    snappy

