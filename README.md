# HiBench Suite  #
## HiBench - the micro-benchmark suite for Hadoop and Spark ##

---

- Current version: 4.0
- Release data: TBD
- Contact: [Lv Qi](mailto:qi.lv@intel.com), [Grace Huang](mailto:jie.huang@intel.com)
- Homepage: https://github.com/intel-bigdata/Sparkbench

- Contents:
  1. Overview
  2. Getting Started
  3. Running

---
### OVERVIEW ###

This benchmark suite contains 10 typical micro workloads. This benchmark suite also has options for users to enable input/output compression for most workloads with default compression codec (zlib). Some initial work based on this benchmark suite please refer to the included ICDE workshop paper (i.e., WISS10_conf_full_011.pdf).

Note: 
 1. Since HiBench-2.2, the input data of benchmarks are all automatically generated by their corresponding prepare scripts.
 2. Since 3.0, it introduces Yarn support
 3. Since 4.0, it consists of more workload implementations on both Hadoop MR and Spark. For Spark, three different APIs including Scala, Java, Python are supportive.

  **Micro benchmarks:**

1. Sort (sort)

    This workload sorts its *text* input data, which is generated using RandomTextWriter.

2. WordCount (wordcount)

    This workload counts the occurrence of each word in the input data, which are generated using RandomTextWriter. It is representative of another typical class of real world MapReduce jobs - extracting a small amount of interesting data from large data set.
	
3. TeraSort (terasort)

	TeraSort is a standard benchmark created by Jim Gray. Its input data is generated by Hadoop TeraGen example program.

4. Sleep (sleep)

    This workload sleep an amount of seconds in each task to test framework scheduler.

  **SQL:**

5. Scan (scan), Join(join), Aggregate(aggregation)

   This workload is developed based on SIGMOD 09 paper "A Comparison of Approaches to Large-Scale Data Analysis" and HIVE-396. It contains Hive queries (Aggregation and Join) performing the typical OLAP queries described in the paper. Its input is also automatically generated Web data with hyperlinks following the Zipfian distribution.

  **Web Search Benchmarks:**

6. PageRank (pagerank)

    This workload benchmarks PageRank algorithm implemented in Spark-MLLib/Hadoop (a search engine ranking benchmark included in pegasus 2.0) examples. The data source is generated from Web data whose hyperlinks follow the Zipfian distribution.
	
7. Nutch indexing (nutchindexing)

	Large-scale search indexing is one of the most significant uses of MapReduce. This workload tests the indexing sub-system in Nutch, a popular open source (Apache project) search engine. The workload uses the automatically generated Web data whose hyperlinks and words both follow the Zipfian distribution with corresponding parameters. The dict used to generate the Web page texts is the default linux dict file /usr/share/dict/linux.words.

  **Machine Learning:**

8. Bayesian Classification (bayes)

    This workload benchmarks NaiveBayesian Classification implemented in Spark-MLLib/Mahout examples.

    Large-scale machine learning is another important use of MapReduce. This workload tests the Naive Bayesian (a popular classification algorithm for knowledge discovery and data mining)  trainer in Mahout 0.7, which is an open source (Apache project) machine learning library. The workload uses the automatically generated documents whose words follow the zipfian distribution. The dict used for text generation is also from the default linux file /usr/share/dict/linux.words.

9. K-means clustering (kmeans)

    This workload tests the K-means (a well-known clustering algorithm
    for knowledge discovery and data mining) clustering in Mahout 0.7/Spark-MLlib. The input data set is generated by GenKMeansDataset based on Uniform Distribution and Guassian Distribution.

	**HDFS Benchmarks:**

10. enhanced DFSIO (dfsioe)

    Enhanced DFSIO tests the HDFS throughput of the Hadoop cluster by generating a large number of tasks performing writes and reads simultaneously. It measures the average I/O rate of each map task, the average throughput of each map task, and the aggregated throughput of HDFS cluster. 
    Note: this benchmark doesn't have Spark corresponding implementation.
---
### Getting Started ###

2. Prerequisites

  0. Network configurations

      Setup SSH public/private key pair, and disable
      `StrictHostKeyChecking` in `/etc/ssh/ssh_config`. Make sure all
      nodes in your cluster can ssh to each other nodes (including
      localhost) without prompt for password.

      Double check in each node, make sure all hostnames in the
      cluster will be resolved to right IP addresses.

  1. Setup JDK-1.6(suggested)

      Download Oracle-JDK-1.6 and setup properly.

      Note: Due to
      [SPARK-1703](https://issues.apache.org/jira/browse/SPARK-1703)
      and
      [SPARK-1911](https://issues.apache.org/jira/browse/SPARK-1911),
      Oracle-JDK-1.6 is the suggested option which passes all tests.

      Other JDK versions such as Oracle-JDK-1.7 and Oracle-JDK-1.8 are
      also supported if python related workloads can be discarded or
      running under standalone mode.

  2. Setup Hadoop

      Before you run any workload in the package, please verify the
      Hadoop framework is running correctly. Both MR1 and MR2 from
      Apahce, CDH4 and CDH5 are supported & tested. 

      Note: For CDH5/MR1 with tarball, please recreate symlink file
      `hadoop-*-cdh*/share/hadoop/mapreduce` to point to correct folder:

           cd share/hadoop
           rm mapreduce
           ln -s mapreduce1 mapreduce

  3. Setup Spark

      Download/Checkout spark from
      [https://github.com/apache/spark](https://github.com/apache/spark).
      Use spark 1.2.0 or later versions.

      For hadoop 1.0.4, standalone mode only:
      
      `./make-distribution.sh --name spark --tgz -Phive`

      For hadoop with YARN support:

      `./make-distribution.sh --name spark-yarn --tgz -Phive -Pyarn -Phadoop-2.x`
      
      Please refer to `Known Issues` to set `conf/spark-default.conf`
      properly.

  4. Setup HiBench

      Download/checkout HiBench benchmark suite from
      [https://github.com/Intel-bigdata/Sparkbench/tree/v4.0-branch](https://github.com/Intel-bigdata/Sparkbench/archive/v4.0-branch.zip)
      
      Edit `src/pom.xml`, set `spark.version` and `spark.bin.version`
      according to your spark version. Currently, `spark.bin.version`
      must be set to `1.2` or `1.3`.

      Begin from HiBench V4.0, HiBench'll need python 2.x(>=2.6) for
      running. For most modern linux distribution, this is satifised
      already.

  5. Setup `numpy` in all nodes for Python related MLLib workloads. (numpy version > 1.4)

     For CentOS(6.2+):
     
     `yum inlstall numpy`

     For Ubuntu/Debian:

     `aptitude install python-numpy`

  6. Setup for HiBench/report_gen_plot.py (Optional)
  
     Install python-matplotlib with verion of 0.9+

     For CentOS(6.2+):
     
     `yum inlstall python-matplotlib`

     For Ubuntu/Debian:

     `aptitude install python-matplotlib`

2. Configure

     Quick start for minimum requirements: edit
     `conf/99-user_defined_properties.conf`, make sure below
     properties has been set:

          hibench.hadoop.home      The Hadoop installation location
          hibench.spark.home       The Spark installation location
          hibench.hdfs.master      HDFS master
          hibench.spark.master     SPARK master
	  
     Note: For YARN mode, set `hibench.spark.master` to
     `yarn-client`. (`yarn-cluster` is not supported yet)

     Parallelism, memory, exector number tuning:
     
          hibench.default.map.parallelism       Mapper numbers in MR, 
                                                partition numbers in Spark
          hibench.default.shuffle.parallelism   Reducer numbers in MR, shuffle 
                                                partition numbers in Spark
          hibench.yarn.exectors.num             Number executors in YARN mode
          hibench.yarn.exectors.cores           Number executor cores in YARN mode 
          spark.exectors.memory                 Executor memory, standalone or YARN mode
          spark.driver.memory                   Driver memory, standalone or YARN mode
          
     Compress options:

          hibench.compress.profile              Compression option `enable` or `disable`
          hibench.compress.codec.profile        Compression codec, `snappy`, `lzo` or `default`
     
     Data scale profile selection:

          hibench.scale.profile                 Data scale profile, `tiny`, `small`, `large`
                                                  
     You can add more data scale profiles in
     `conf/10-data-scale-profile.conf`. And please don't change
     `conf/00-default-properties.conf` if you have no confidence.

3. Configure parsing sequence and rules:

     1. All configurations will be loaded in a nested folder structure:

              conf/*.conf                                         Configure globally
              workloads/<workload>/conf/*.conf                    Configure for each workload
              workloads/<workload>/<language APIs>/.../*.conf     Configure for various languages

     2. For configurations in same folder, the loading sequence will be
     sorted according to configure file name. 

     3. Values in latter configures will override former.

     4. The final values for all properties will be stored in a single
     config file located at `report/<workload><language APIs>/conf/<workload>.conf`,
     which contain all values and pinpoint the source of the configures.

     5. All `spark.*` properties will be passed to Spark runtime configuration.

3. Configure each workload

    You can add a new data scale profile in
    `conf/10-data-scale-profile.conf`. Or edit
    `workloads/<workload>/conf/00-<workload>-default.conf` for each
    workload directly. However, latter approach will broke data scale
    profile selection mechanism, which is not suggested.

4. Synchronize the time on all nodes (optional but highly recommended)

5. Build

    Run `bin/build-all.sh` will build HiBench for all running
    environments:

          - MR1, Spark1.2
          - MR1, Spark1.3
          - MR2, Spark1.2
          - MR2, Spark1.3

    You can build on your own by `mvn clean package` in `src` folder:

          cd <HiBench root>/src
          mvn clean package

    By default it will build HiBench with MR2 and spark1.3 API.

    For running HiBench with MR1 API, supply `-DMR1`, and for
    running HiBench with Spark1.2 API, supply `-Dspark1.2`. For
    example, building Hibench with MR1 and Spark1.2 API:

          cd <HiBench root>/src
          mvn clean package -D MR1 -D spark1.2

    Remember to update values of `hibench.hadoop.home` and
    `hibench.spark.home` in `conf/99-user_defined_properties.conf`
    accordingly.
          
---
### Running ###

- Run several workloads sequentially

  The `conf/benchmarks.lst` file under the package folder defines the
  workloads to run when you execute the `bin/run-all.sh` script under
  the package folder. Each line in the list file specifies one
  workload. You can use `#` at the beginning of each line to skip the
  corresponding bench if necessary.

- Run each workload separately

  You can also run each workload separately. In general, there are 3
  different files under one workload folder.

      prepare/prepare.sh            Generate or copy the job input 
                                    data into HDFS.
      mapreduce/bin/run.sh          run MapReduce language API
      spark/java/bin/run.sh         run Spark/java language API
      spark/scala/bin/run.sh        run Spark/scala language API
      spark.python/bin/run.sh       run Spark/python language API
      

  Follow the steps below to run a workload:

  1. Configure the benchmark:

      Set or override properties values for hibench and spark by
      modifying `<workload>/conf/*.conf` and `<workload>/<language
      APIs>/*.conf` if necessary.

  2. Prepare data:

      `prepare/prepare.sh` to prepare input data in HDFS for running the
      benchmark.

  3. Run the benchmark:

      `<workload>/<language APIs>/bin/run.sh` to run the corresponding benchmark.

  4. View the detailed report for each workloads:

      - `report/<workload>/<language APIs>/bench.log`: raw logs on client side.
      - `report/<workload>/<language APIs>/monitor.html`: System monitor charts.
      - `report/<workload>/<language APIs>/conf/<workload>.conf`: Generated environment variable configuration for this workload.
      - `report/<workload>/<language APIs>/conf/sparkbench/<workload>/sparkbench.conf`: Generated configuration for this workloads, which is used for mapping to environment variable.
      - `report/<workload>/<language APIs>/conf/sparkbench/<workload>/spark.conf`: Generated configuration for spark.

  5. Plot the report:
      
      `<HiBench root>/bin/report_gen_plot.py report/hibench.report` to
      generate report figures.

      Note:
      
        `report_gen_plot.py` requires `python2.x` and `python-matplotlib`.

---
### Known issues ###

    
